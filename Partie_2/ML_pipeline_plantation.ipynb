{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3bafac",
   "metadata": {},
   "source": [
    "# Projet : Préparer les données, former et évaluer des modèles ML\n",
    "\n",
    "Notebook prêt à exécution. Suis les consignes : pipelines scikit-learn, plusieurs modèles non réglés, réglage hyperparamètres et évaluation finale.\n",
    "\n",
    "**Source des données :**\n",
    "https://data.metropolegrenoble.fr/visualisation/table/?id=arbres-grenoble&disjunctive.sous_categorie_desc&disjunctive.espece\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a5bc1",
   "metadata": {},
   "source": [
    "## 0) Instructions avant exécution\n",
    "\n",
    "- Si tu as accès à Internet dans ton environnement Jupyter : laisse `DATA_PATH` sur l'URL CSV ou sur le lien direct CSV.\n",
    "- Si pas d'accès Internet, télécharge le CSV localement et remplace `DATA_PATH` par le chemin local (ex: `'/chemin/arbres.csv'`).\n",
    "- Ce notebook suppose que l'année de plantation est contenue dans une colonne nommée `annee_de_plantation` ou similaire : adapte le nom de colonne si nécessaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae3d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 1) Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('Librairies importées')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165fd2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 2) Charger les données (modifier DATA_PATH si nécessaire)\n",
    "# Remarque : l'URL de la page web fournie n'est pas nécessairement le lien direct CSV.\n",
    "# Remplace DATA_PATH par le CSV direct ou le chemin local.\n",
    "\n",
    "DATA_PATH = 'https://data.metropolegrenoble.fr/explore/dataset/arbres-grenoble/download/?format=csv&timezone=Europe/Paris&lang=fr'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print('Données chargées depuis :', DATA_PATH)\n",
    "except Exception as e:\n",
    "    print('Impossible de charger depuis l'URL dans cet environnement.')\n",
    "    print('Erreur :', e)\n",
    "    print(\"Place ici le chemin local vers le fichier CSV, par ex : '/home/user/arbres.csv'\")\n",
    "    df = None\n",
    "\n",
    "# Afficher les 5 premières lignes si le chargement a réussi\n",
    "if df is not None:\n",
    "    display(df.head())\n",
    "    print('\\nColonnes :', list(df.columns)[:30])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a10ca2",
   "metadata": {},
   "source": [
    "## 3) Préparation : identifier la cible et les features\n",
    "\n",
    "- **Cible (target)** : `annee_de_plantation` (adapte si le nom diffère)\n",
    "- **Features** : sélectionner colonnes pertinentes (ex : espèce, circonférence, hauteur, arrondissement, type de voirie, etc.)\n",
    "\n",
    "> Assure-toi d'adapter `TARGET_COL` et la liste `FEATURE_COLS` selon les colonnes réellement présentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fba5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 3a) Paramétrage cible / features (adapte ces noms si nécessaire)\n",
    "TARGET_COL = 'annee_de_plantation'  # adapte si le nom est différent\n",
    "# Exemple générique : on va automatiquement choisir les colonnes numériques et catégorielles\n",
    "\n",
    "if df is not None:\n",
    "    # détecter colonnes numériques et catégorielles\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    # retirer la cible si détectée automatiquement\n",
    "    if TARGET_COL in num_cols:\n",
    "        num_cols.remove(TARGET_COL)\n",
    "    if TARGET_COL in cat_cols:\n",
    "        cat_cols.remove(TARGET_COL)\n",
    "    print('Numériques candidates:', num_cols[:10])\n",
    "    print('Catégorielles candidates:', cat_cols[:10])\n",
    "else:\n",
    "    num_cols = []\n",
    "    cat_cols = []\n",
    "\n",
    "# Exemple : garder un sous-ensemble si beaucoup de colonnes\n",
    "FEATURE_NUM = num_cols[:10]\n",
    "FEATURE_CAT = cat_cols[:6]\n",
    "print('\\nFeatures numériques retenues (exemple):', FEATURE_NUM)\n",
    "print('Features catégorielles retenues (exemple):', FEATURE_CAT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a12430",
   "metadata": {},
   "source": [
    "## 4) Visualisation rapide (au moins 1 graphique)\n",
    "- Histogramme de la variable cible\n",
    "- Diagramme de corrélation ou scatter simple si possible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed4b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 4) Visualisation simple\n",
    "if df is not None and TARGET_COL in df.columns:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    vals = df[TARGET_COL].dropna()\n",
    "    plt.hist(vals, bins=30)\n",
    "    plt.title('Distribution de ' + TARGET_COL)\n",
    "    plt.xlabel(TARGET_COL)\n",
    "    plt.ylabel('Effectif')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Colonne cible non trouvée dans le dataframe. Vérifie TARGET_COL.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489cdb1c",
   "metadata": {},
   "source": [
    "## 5) Baseline naïf\n",
    "- Créer un modèle DummyRegressor (par ex. stratégie='mean') et évaluer sur l'ensemble d'entraînement comme demandé par la consigne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 5) Baseline naïf (sur l'ensemble d'entraînement)\n",
    "if df is not None and TARGET_COL in df.columns:\n",
    "    # enlever lignes sans cible\n",
    "    df_clean = df.dropna(subset=[TARGET_COL]).copy()\n",
    "    X = df_clean.drop(columns=[TARGET_COL])\n",
    "    y = df_clean[TARGET_COL]\n",
    "    # utiliser un train_test_split pour garder un test final\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    dummy = DummyRegressor(strategy='mean')\n",
    "    # pour baseline demandé, on évalue sur l'ensemble d'entraînement\n",
    "    # mais on gardera aussi les scores sur l'ensemble test\n",
    "    # créer pipelines simples pour que Dummy fonctionne avec DataFrame\n",
    "    dummy.fit(X_train.select_dtypes(include=[np.number]), y_train)\n",
    "    y_pred_train = dummy.predict(X_train.select_dtypes(include=[np.number]))\n",
    "    train_rmse = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "    print('Baseline (mean) RMSE on TRAIN:', train_rmse)\n",
    "else:\n",
    "    print('Données manquantes ou cible introuvable, impossible de construire baseline.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49064d5e",
   "metadata": {},
   "source": [
    "## 6) Pipelines et modèles non réglés\n",
    "- Prétraitement : imputeur + scaler pour numériques, imputeur + OneHot pour catégoriques\n",
    "- Tester au moins 3 modèles non réglés : LinearRegression, DecisionTreeRegressor, RandomForestRegressor (n_estimators=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b438a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 6) Prétraitement et évaluation de modèles non réglés\n",
    "if df is not None and TARGET_COL in df.columns:\n",
    "    # construire ColumnTransformer\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, FEATURE_NUM),\n",
    "        ('cat', categorical_transformer, FEATURE_CAT)\n",
    "    ], remainder='drop')\n",
    "\n",
    "    # modèles à tester\n",
    "    models = {\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "        'RandomForest_n10': RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('model', model)])\n",
    "        pipe.fit(X_train[FEATURE_NUM+FEATURE_CAT], y_train)\n",
    "        y_pred = pipe.predict(X_test[FEATURE_NUM+FEATURE_CAT])\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        results[name] = {'rmse': rmse, 'r2': r2}\n",
    "        print(f\"{name} -> RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "else:\n",
    "    print('Données manquantes ou cible introuvable.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf982935",
   "metadata": {},
   "source": [
    "## 7) Choisir un modèle prometteur et régler ses hyperparamètres\n",
    "- Exemple : on choisit RandomForest et on ajuste `n_estimators`, `max_depth` et `max_features` via GridSearchCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5111b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 7) GridSearchCV sur RandomForest (exemple)\n",
    "if df is not None and TARGET_COL in df.columns:\n",
    "    rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                  ('model', RandomForestRegressor(random_state=42))])\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [50, 100],\n",
    "        'model__max_depth': [None, 10, 20],\n",
    "        'model__max_features': ['auto', 'sqrt']\n",
    "    }\n",
    "    grid = GridSearchCV(rf_pipeline, param_grid, cv=3, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "    grid.fit(X_train[FEATURE_NUM+FEATURE_CAT], y_train)\n",
    "    print('Meilleurs paramètres :', grid.best_params_)\n",
    "    best = grid.best_estimator_\n",
    "    y_pred_best = best.predict(X_test[FEATURE_NUM+FEATURE_CAT])\n",
    "    rmse_best = mean_squared_error(y_test, y_pred_best, squared=False)\n",
    "    r2_best = r2_score(y_test, y_pred_best)\n",
    "    print(f\"RandomForest (réglé) -> RMSE test: {rmse_best:.4f}, R2 test: {r2_best:.4f}\")\n",
    "else:\n",
    "    print('Données manquantes ou cible introuvable.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c740f130",
   "metadata": {},
   "source": [
    "## 8) Exporter / sauvegarder le pipeline final\n",
    "- Sauvegarder l'estimateur `best` via joblib pour réutilisation en production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 8) Sauvegarder le modèle\n",
    "if 'best' in globals():\n",
    "    import joblib\n",
    "    joblib.dump(best, 'pipeline_rf_best.joblib')\n",
    "    print('Pipeline sauvegardée : pipeline_rf_best.joblib')\n",
    "else:\n",
    "    print('Aucun modèle `best` trouvé (GridSearch non exécuté).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b546dd47",
   "metadata": {},
   "source": [
    "## 9) Résumé des livrables attendus\n",
    "- Au moins une visualisation (histogramme de la cible inclus ci-dessus)\n",
    "- Un pipeline scikit-learn pour prétraitement et modèle (`preprocessor` + `model`)\n",
    "- Évaluation de performances pour au moins trois modèles non réglés (affiché)\n",
    "- Évaluation des performances d'un modèle final réglé (affiché si GridSearch exécuté)\n",
    "\n",
    "---\n",
    "\n",
    "*Fin du notebook. Adapte `TARGET_COL`, `FEATURE_NUM` et `FEATURE_CAT` selon ton jeu de données réel avant exécution.*\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
