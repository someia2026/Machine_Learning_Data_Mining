{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML1 - GridSearch avec DecisionTreeRegresson, RandomForestRegressor\n",
    "\n",
    "Ce notebook fait suite au notebook ML1_Pipeline_Model et se concentre sur :\n",
    "1. L'utilisation de DecisionTreeRegressor et RandomForestRegressor ou d'autres\n",
    "2. L'optimisation des hyperparam√®tres avec GridSearchCV\n",
    "3. La validation crois√©e (cross-validation)\n",
    "\n",
    "## 1. Import des biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les libraries n√©cessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement et pr√©paration des donn√©es avec le PipeLine.\n",
    "\n",
    "Nous reprenons les m√™mes √©tapes de pr√©paration que dans le notebook pr√©c√©dent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donn√©es depuis le fichier pickle\n",
    "\n",
    "with open(\"df_trees.pkl\", \"rb\") as f:\n",
    "    df_clean = pd.read_pickle(f)\n",
    "df_clean = pd.read_pickle(\"df_trees.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-validation initiale\n",
    "\n",
    "Avant d'optimiser les hyperparam√®tres, √©valuons un mod√®le avec les param√®tres par d√©faut en utilisant la validation crois√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation crois√©e initiale sans optimisation des hyperparam√®tres\n",
    "# On peut aussi imprimer les scores MSE ou MAE de chaque cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. üå≥ Mod√©lisation avec GridSearchCV\n",
    "\n",
    "Choisissons deux models de machine learning.\n",
    "\n",
    "√âvaluer les mod√®les avec optimisation (en testant diff√©rentes valeurs des hyperparam√®tres).\n",
    "Optimisez les mod√®les comme vous le souhaitez, par exemple pour l'arbre des des decisions et for√™t al√©atoire :\n",
    "\n",
    "### üîç Hyperparam√®tres test√©s\n",
    "- `max_depth`: profondeur maximale des arbres [3, 4, 5, 10]\n",
    "- `min_samples_leaf`: nombre minimum d'√©chantillons requis dans une feuille [0.1, 0.05]\n",
    "- `n_estimators` (pour la for√™t al√©atoire uniquement) : nombre d'arbres dans la foret [50, 100, 200]\n",
    "\n",
    "Utilisons GridSearchCV pour automatiser la recherche des meilleurs hyperparam√®tres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation des hyperparam√®tres avec GridSearchCV et on peut imprimer les score MSE ou MAE de chauque cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tranformation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__n_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#'model__min_samples_split': [2, 5, 10]\u001b[39;00m\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Cr√©er un pipeline pour le mod√®le Random Forest\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m pipeline_rf \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, tranformation),\n\u001b[0;32m     12\u001b[0m                               (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Initialiser GridSearchCV\u001b[39;00m\n\u001b[0;32m     15\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline_rf, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tranformation' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Param√®tres √† tester pour Random Forest\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [None, 1, 2, 3],\n",
    "    #'model__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Cr√©er un pipeline pour le mod√®le Random Forest\n",
    "pipeline_rf = Pipeline(steps=[('preprocessor', tranformation),\n",
    "                              ('model', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "# Initialiser GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline_rf, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Effectuer la recherche\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs hyperparam√®tres trouv√©s\n",
    "print(\"Meilleurs param√®tres:\", grid_search.best_params_)\n",
    "\n",
    "# Meilleur mod√®le\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# √âvaluation sur l'ensemble de test\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Erreur quadratique moyenne (MSE) sur l'ensemble de test : {mse_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. √âvaluation finale sur le set de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour l'evaluation du meilleur mod√®le sur le set de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisation des pr√©dictions\n",
    "Un seul model suffira."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des pr√©dictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. [OPTIONNEL] Importance des features\n",
    "\n",
    "En utilisant la for√™t al√©atoire, comment peut-on savoir quelles sont les features les plus importantes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code, et √† votre avis, comment c'etait calcul√© l'importance des features dans la for√™t al√©atoire ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
