{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - Classical approach\n",
    "\n",
    "Signification des √©moticones :\n",
    "- üåû : documentations importantes\n",
    "- üëÄ : documentations int√©ressantes √† conna√Ætre\n",
    "- üåö : en compl√©ment\n",
    "- (vide) : √† vous de voir\n",
    "\n",
    "The objective of this notebook is to introduce the *classical approach to linear regression*. It will help you understand:\n",
    "* When you would use a classical statistical approach as opposed to a *machine learning* approach\n",
    "* How to implement classic linear regression in python\n",
    "* üëÄ How to use the [statsmodels](https://www.statsmodels.org/stable/index.html) library\n",
    "* How to select variables to include in a model using a classical *model selection* approach\n",
    "* How to implement and interpret residual plots for model checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce notebook est de pr√©senter l'approche classique de la r√©gression lin√©aire. Il vous aidera √† comprendre :\n",
    "* Quand utiliser une approche statistique classique plut√¥t qu'une approche d'apprentissage automatique\n",
    "* Comment impl√©menter la r√©gression lin√©aire classique en Python\n",
    "* üëÄ Comment utiliser la biblioth√®que [statsmodels](https://www.statsmodels.org/stable/index.html)\n",
    "* Comment s√©lectionner les variables √† inclure dans un mod√®le √† l'aide d'une approche classique de *s√©lection de mod√®le*\n",
    "* Comment mettre en ≈ìuvre et interpr√©ter les graphiques r√©siduels pour la v√©rification du mod√®le\n",
    "\n",
    "Traduit avec DeepL.com (version gratuite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåö Help : Book ISL\n",
    "https://trevorhastie.github.io/ISLR/\n",
    "\n",
    "<img src=\"./images/ISLcover.jpg\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.13.5)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we mean by linear regression?\n",
    "\n",
    "At the moment there is often a battle between the traditional discipline of statistics and the relatively new discipline of data science. In general it seems more 'classic' statistical modelling can sometimes be more interpretable, whereas 'algorithmic modelling' from data science/computer science fields can *sometimes* offer more practical prediction capabilities.\n",
    "\n",
    "<img src=\"./images/ml_xkcd.png\" width=\"300px\">\n",
    "\n",
    "There has been some attempt at the formalisation of this discussion, and calls for the two fields to work more closely together.\n",
    "\n",
    ">\"There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.\"\n",
    ">\n",
    ">üåö [*Leo Breiman*,  Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author), *Statistical Science*, Volume 16, Issue 3 (2001), pp.199-231.](https://projecteuclid.org/euclid.ss/1009213726)\n",
    "\n",
    "In practice it is often difficult to seperate the two disciplines as there is a lot of overlap between the two. There is also a lot of interchangable terminology, i.e. terms which are used by each discipline which often mean the same thing but have different names. This includes peoples CVs...\n",
    "\n",
    "<img src=\"./images/trek.jpg\" width=\"300px\">\n",
    "\n",
    "We will not focus too much energy this debate. However it is important to understand how to frame the type of problem you are working on in order that you can choose a suitable approch/methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One such area where this difference can be confusing is when using *linear regression*. Both traditional statisticians and data scientists use linear regression, but often apply this using two different approaches. \n",
    "\n",
    "Both approaches attempt to estimate an *output variable*, $Y$, based on *input variables*, $X$. Where there can be any number of input variables $p$, i.e. $X$ = ($X_1$, $X_2$,...,$X_p$). We assume there is some relationship between $Y$ and $X$ which we denote by $f$. $œµ$ denotes the *error term* which is independent of $X$.\n",
    "\n",
    "<div style=\"font-size: 100%;\" align= \"center\"> \n",
    "Y = f(X) + œµ\n",
    "</div>\n",
    "\n",
    "Linear regression is an example of a *parametric* method for which we make an assumption about the form of $f$ (the assumption being that it is linear in $X$).\n",
    "\n",
    "<div style=\"font-size: 100%;\" align= \"center\">  \n",
    "Y = Œ≤_0 + Œ≤_1 X_1 + Œ≤_2 X_2 + ... + Œ≤_p X_p + œµ_i\n",
    "</div>\n",
    "\n",
    "For only a single input variable $X$ we would simply have:\n",
    "<div style=\"font-size: 100%;\" align= \"center\">  \n",
    "Y = Œ≤_0 + Œ≤_1 X_1 + œµ_i\n",
    "</div>\n",
    "\n",
    "Which is the same as the formula you will have seen before in school:\n",
    "\n",
    "<div style=\"font-size: 100%;\" align= \"center\"> \n",
    "y = c+ mx\n",
    "</div>\n",
    "\n",
    "NOTE: The input variables or $X$ values are reffered to be many names: *predictors, independent variables, features,* or sometimes just *variables* (depending on which field you work in). Similarly the *output variable* (usually denoted $Y$) can be sometimes referred to as the *response, target* or *dependent variables*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qu'entend-on par r√©gression lin√©aire ?\n",
    "\n",
    "√Ä l'heure actuelle, il existe souvent un conflit entre la discipline traditionnelle des statistiques et la discipline relativement nouvelle de la science des donn√©es. En g√©n√©ral, il semble que la mod√©lisation statistique ¬´ classique ¬ª soit parfois plus facile √† interpr√©ter, tandis que la ¬´ mod√©lisation algorithmique ¬ª issue des domaines de la science des donn√©es et de l'informatique peut *parfois* offrir des capacit√©s de pr√©diction plus pratiques.\n",
    "\n",
    "<img src=\"./images/ml_xkcd.png\" width=\"300px\">\n",
    "\n",
    "Certaines tentatives ont √©t√© faites pour formaliser cette discussion et encourager les deux domaines √† collaborer plus √©troitement.\n",
    "\n",
    "¬´ Il existe deux cultures dans l'utilisation de la mod√©lisation statistique pour tirer des conclusions √† partir de donn√©es. L'une suppose que les donn√©es sont g√©n√©r√©es par un mod√®le stochastique donn√©. L'autre utilise des mod√®les algorithmiques et traite le m√©canisme des donn√©es comme inconnu. La communaut√© statistique s'est engag√©e √† utiliser presque exclusivement des mod√®les de donn√©es. Cet engagement a conduit √† des th√©ories non pertinentes, √† des conclusions discutables et a emp√™ch√© les statisticiens de travailler sur un large √©ventail de probl√®mes actuels int√©ressants. La mod√©lisation algorithmique, tant en th√©orie qu'en pratique, s'est d√©velopp√©e rapidement dans des domaines autres que la statistique. Elle peut √™tre utilis√©e √† la fois sur des ensembles de donn√©es complexes et volumineux et comme alternative plus pr√©cise et plus informative √† la mod√©lisation de donn√©es sur des ensembles de donn√©es plus petits. Si notre objectif en tant que domaine est d'utiliser les donn√©es pour r√©soudre des probl√®mes, nous devons alors nous √©loigner de la d√©pendance exclusive aux mod√®les de donn√©es et adopter un ensemble d'outils plus diversifi√©. ¬ª\n",
    ">\n",
    ">üåö [*Leo Breiman*,  Mod√©lisation statistique : les deux cultures (avec commentaires et r√©plique de l'auteur), *Statistical Science*, volume 16, num√©ro 3 (2001), pp.199-231.](https://projecteuclid.org/euclid.ss/1009213726)\n",
    "\n",
    "Dans la pratique, il est souvent difficile de s√©parer les deux disciplines, car elles se recoupent largement. Il existe √©galement de nombreux termes interchangeables, c'est-√†-dire des termes utilis√©s par chaque discipline qui ont souvent la m√™me signification, mais des noms diff√©rents. Cela inclut les CV des personnes...\n",
    "\n",
    "<img src=\"./images/trek.jpg\" width=\"300px\">\n",
    "\n",
    "Nous ne nous attarderons pas trop sur ce d√©bat. Cependant, il est important de comprendre comment d√©finir le type de probl√®me sur lequel vous travaillez afin de pouvoir choisir une approche/m√©thodologie appropri√©e.\n",
    "\n",
    "Traduit avec DeepL.com (version gratuite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical or Machine Learning approach?\n",
    "Chapter 2 in **ISLR** gives a great introduction to this issue (and the chapter explains the basis of everything that you will do/learn over the linear regression and the machine learning modules). For this exercise you need to understand there are broadly two main approaches in which we may wish to use linear regression: the classical statistical approach and a more algorithmic/machine learning approach. \n",
    "\n",
    "Broadly:\n",
    "\n",
    "We may use a **Classical statistical** approach when we are interested in understanding and quantifying the relationship between $Y$ and $x$ (or $x$'s). i.e. what affect does a change in $x$ make to $Y$. \n",
    "\n",
    "A **ML (Prediction)** approach can be used when we are focussed solely on creating a model which can take inputs $X_{1}$, $X_{2}$ ...$X_{p}$ and can return a prediction of $Y$.\n",
    "\n",
    "Feel free to argue with these definitions, the authors of ISLR themselves agree the cross-over between ML and classic statsitical methods is very often not clear, but they will help you answer the questions below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - defining types of problems\n",
    "\n",
    "Write down, for each case below, whether you would use a **classical statistical** approach or a **ML prediction** approach to solve the problem.\n",
    "\n",
    "1. A company approaches you who are interested in conducting a direct-marketing campaign. The goal is to identify individuals who will respond positively to a mailing, based on observations of demographic variables measured on each individual. They will then only mail those who they think will respond positively to mailing in order to have maximum impact for minimum cost.\n",
    "\n",
    "<img src=\"./images/letters.jpg\" width=\"300px\">\n",
    "\n",
    "\n",
    "2. You have been contacted by Nicolas Cage. He has many offers for roles in new upcoming movies but cannot accept them all. He wishes to use historical data to determine which of the movies being offered are likely to be the greatest success. He defines sucess as the greater amount of money a movie made. He explains he wants to know which factors, i.e. number of award winning actresses, budget, movie length etc, are most important in determining a movies' success.\n",
    "\n",
    "<img src=\"./images/Nic.jpg\" width=\"300px\">\n",
    "\n",
    "\n",
    "3. An international charity \"Water for All\" has contacted you. They have been collecting usage, current status (working/not-working) & maintence data on rural-community water pumps across several countries in Africa. They wish to know if it possible to use mathematical models to understand when future failure of each water pump will occur. This will allow them to dispatch their teams in advance to provide protective maintenance to prevent the pump failure.\n",
    "\n",
    "<img src=\"./images/water_pump.jpg\" width=\"300px\">\n",
    "\n",
    "\n",
    "4. You have just been employed by the Grenoble police department as their first data scientist. They are excited for you to arrive as they have been told by a very expensive management consulant that 'data science' is the future of policing. They have collated all information they have on the dates, times, geographic location and hand written reports of historical crimes in Grenoble over the last decade. They are waiting for you to tell them where the next crime will happen so they can dispatch their officers in advance to catch the bad guys before the crime occurs!\n",
    "\n",
    "\n",
    "5. *The Irresistable Cholocolate Company* has begun testing new recipes of chocolate. They have hired Sean Bean as their new head of research. With his insistence their consumer model is now to make chocolate so irresistable that customers have no choice but finish it as soon as possible, and then have to buy more... hence increasing sales. Their new recipe contains a *secret ingredient*, which is not disclosed. It is unclear if the new recipe will pass legal standards, but regardless, the research team have begun consumer testing. They have been creating chocolate bars with different proportions of this ingredient and have been measuring the time it takes for customers to consume the whole bar. Mr Bean would like to know more about how the proportion of the secret ingredient added affects the time taken to consume the bar. This will allow his research team to perfect the new recipe. \n",
    "\n",
    "<img src=\"./images/choc.jpg\" width=\"200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answers here: (choose 'classical' or 'ML')**\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing linear regression in python\n",
    "\n",
    "The rest of this notebook is focussed only on using a classic linear regression approach.\n",
    "\n",
    "Let's make some random data for us to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25)\n",
    "x = np.random.normal(size = 40)\n",
    "y = 1.6*x + np.random.normal(size = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'o', label='random data')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you already know there are many excellent 3rd party libraries in python that you can import, so that you dont have to write all the code yourself. It turns out scipy has a function that allows us to do linear regression that a kind open source developer has already made for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'o', label='original data')\n",
    "plt.plot(x, intercept + slope*x, 'r', label='fitted line')\n",
    "plt.plot(x, slope*x, 'green', label='fitted line only slope')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the slope and intercept of the fitted model, which allow us to create the plot above, the function ```linregress()``` also returns other information when it is called.\n",
    "\n",
    "**Task 1:** \n",
    "* Print the slope and intercept, do they match what you think it should be based on the plot and equation used to generate the data?\n",
    "* What is the correlation coefficient of the linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Print slope and intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Correlation coefficient of the linear regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* conduct a linear regression for the arrays x2, y2 below\n",
    "* print slope, intercept, correlation coefficient\n",
    "* make a scatter plot of the data and the fitted regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.array([ 0.22827309,  1.0268903 , -0.83958485, -0.59118152, -0.9568883 ,\n",
    "       -0.22232569, -0.61991511,  1.83790458, -2.05323076,  0.86858305,\n",
    "       -0.92073444, -0.23231186,  2.1529569 , -1.33466147,  0.07637965,\n",
    "       -1.24608928,  1.20227231, -1.04994158,  1.05661011, -0.41967767,\n",
    "        2.29484234, -2.59448738,  2.8227564 ,  0.68088892, -1.57769345,\n",
    "       -1.97625359,  0.53333982, -0.29086971, -0.51351967,  1.98262608,\n",
    "        0.22600105, -1.83990496,  1.60767083,  0.38829194,  0.39973206,\n",
    "        0.4054766 ,  0.21700177, -0.6334391 ,  0.24662153, -1.93954552])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = np.array([-0.18269538, -3.2202988 ,  1.33454079,  0.0630553 ,  1.6085824 ,\n",
    "       -0.21392876,  0.58013809, -2.95481368,  2.772595  ,  0.88925045,\n",
    "        2.29120304,  1.96443982, -3.42629745,  3.35625955,  1.07883913,\n",
    "        1.24503731, -2.10728298,  1.65268524, -1.57941313,  1.73556883,\n",
    "       -2.25436816,  3.15079347, -5.2922891 , -0.57261505,  0.89058007,\n",
    "        2.88268935, -0.22134391,  0.95599233,  1.17298232, -3.20390167,\n",
    "       -0.64017069,  0.32593461, -1.32103579,  0.6240868 , -0.35272815,\n",
    "       -1.49437497,  0.20989395,  0.27261366, -0.40530206,  4.48897751])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your solution here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four different datasets: different regression results?\n",
    "\n",
    "We can be tempted to pass the exploratory data analysis step and directly apply a linear regression model to find quick results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:**\n",
    "\n",
    "The file four_datasets.csv in the folder data contains four small datasets. Find a linear regression model for each of the four sets, **without plotting the data first**. Compare the coefficients. What do you conclude based on this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now make a plot of each dataset, including the linear regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What do you conclude now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statsmodels package \n",
    "\n",
    "Although the scipy package offers many statistical functions, there are more specialised statistical packages on offer such as **statsmodels**. This package allows you to complete linear regression as well as many other statistical methods and test. You can browse its offerings [here](https://www.statsmodels.org/stable/index.html). It uses a syntax and has output close to that of the **R** language and ecosystem, which is specialised statistical software/language.\n",
    "\n",
    "We can use it to model the same random data we looked at above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÄ To better understand how OLS works : https://medium.com/swlh/interpreting-linear-regression-through-statsmodels-summary-4796d359035a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25)\n",
    "x = np.random.normal(size = 40)\n",
    "y = 1.6*x + np.random.normal(size = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "x = sm.add_constant(x) # an intercept term to the model\n",
    "model = sm.OLS(y, x)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:**\n",
    "\n",
    "To help understand the output, write down what the terms being reported mean:\n",
    "* R-squared\n",
    "* coef (regression coefficient)\n",
    "* std err (standard error)\n",
    "* P>|t| (p-value)\n",
    "* [0.025 0.975] (confidence intervals)\n",
    "\n",
    "Write down what *least squares* regression is.\n",
    "\n",
    "NOTE: ISLR introductory chapters explain most of these. If not look them up online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - looking for associations in Emergency Departments\n",
    "\n",
    "Emergency departments across the westernised world are suffering from increasing number of patient visits and find themselves more often overcrowded. Overcrowding has been linked to worse patient health outcomes and waiting times within hospital. The search to understand why this is occuring and what can be done to alleviate overcrowding is currently an [active area of research](https://emj.bmj.com/content/early/2019/11/25/emermed-2018-207917).\n",
    "\n",
    "One theory is that if the main hospital is full then patients will be forced to stay in the Emergency Department as they cannot be moved into the main hospital. This may result in the Emergency Department becoming overcrowded. In the UK patients who are medically fit to return home but are still in hospital are reffered to as 'delayed transfers of care' (or DTOCS for short). The number of occurances of this is measured in hospitals. The number of long waiting times in Emergency Departments (longer than 4 hours) are also recorded.\n",
    "\n",
    "These data are given in temporal order (monthly).\n",
    "\n",
    "Your job as data scientist is to understand if there is a relationship between the numbers of DTOCS and the numbers of long-waits in Emergency Departments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "\n",
    "You must:\n",
    "* load the data\n",
    "* plot the 2 time series with 2 curves\n",
    "* plot then the data as a scatter plot (Y : dtocs, X : long_waits)\n",
    "* run a linear regression using statsmodels\n",
    "* add your regression line to the scatter plot\n",
    "* describe what the p-values, confidence intervals and r-squared values indicate. \n",
    "\n",
    "<details><summary>HINT</summary><br>\n",
    "when adding the regression line the `params` attribute (of the `model` object) contains the fitted coefficients\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dtoc_dataset():\n",
    "    '''\n",
    "    Loads the long_wait and dtoc data sets into memory\n",
    "    Returns a tuple of numpy.ndarrays representing\n",
    "    breach and dtoc dataset respectively.\n",
    "    '''\n",
    "    #note we use skip_header because the dataset has column descriptors\n",
    "    dtocs = np.genfromtxt('./data/dtocs.csv', skip_header=1)\n",
    "    long_waits = np.genfromtxt('./data/long_waits.csv', skip_header=1)\n",
    "    return long_waits, dtocs\n",
    "    \n",
    "    \n",
    "#long_waits, dtocs = load_dtoc_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load and plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot above contains a trend. It seems that over the years, increasing long waits leads to increased dtocs!! But we are interested in whether period change in long_waits is really related to period change in dtocs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another data scientist informs you that there is a problem using linear regression when the data is a time series.\n",
    "üåö Take a look at this link to understand why : https://medium.com/data-science/how-to-model-time-series-data-with-linear-regression-cd94d1d901c0\n",
    "\n",
    "A basic way of dealing with this issue is to take a first difference of the data, to observe whether the evolutions of the 2 features go hand in hand in the short term.\n",
    "To compute the first difference of a series of data, we subtract each value from the subsequent value in the series. \n",
    "\n",
    "You must:\n",
    "* Create a new numpy array which contains the first differenced values of the long_waits array\n",
    "* Create a new numpy array which contains the first differenced values of the DTOCS array\n",
    "* Plot the data as a scatter plot\n",
    "* Perform linear regression using statsmodels on this differenced data\n",
    "* add your regression line to the scatter plot\n",
    "* describe what the p-values, confidence intervals and r-squared values indicate.\n",
    "\n",
    "HINT\n",
    "\n",
    "* Numpy contains a function called ```np.diff()``` that might help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual plots\n",
    "For completenes we need to consider if the assumptions we made when implementing our linear regression are valid. According to **ISTL**\n",
    "> When we fit a linear regression model to a particular data set, many problems may occur. Most common among these are the following:\n",
    "> 1. Non-linearity of the response-predictor relationships.\n",
    "> 2. Correlation of error terms.\n",
    "> 3. Non-constant variance of error terms.\n",
    "> 4. Outliers.\n",
    "> 5. Collinearity.\n",
    ">\n",
    "> In practice, identifying and overcoming these problems is as much an\n",
    "art as a science. Many pages in countless books have been written on this\n",
    "topic. Since the linear regression model is not our primary focus here, we\n",
    "will provide only a brief summary of some key points\n",
    "\n",
    "If you need to know about this in future a good place to start is the overview of these problems **ISLR** section *3.3.3.*. \n",
    "\n",
    "Here we will now focus on how to produce some of the diagnostic plots in python which help us assess these issues. In my experience producing these plots in python sometimes takes a lot more thought/work than using R packages which are specialised for this kind of statistical work. \n",
    "\n",
    "Some other resources:\n",
    "\n",
    "üëÄ https://www.statsmodels.org/dev/examples/notebooks/generated/regression_diagnostics.html\n",
    "\n",
    "üëÄ https://www.statsmodels.org/dev/examples/notebooks/generated/regression_plots.html\n",
    "\n",
    "üåö https://www.statsmodels.org/stable/diagnostic.html\n",
    "\n",
    "üåû https://medium.com/data-science/how-to-use-residual-plots-for-regression-model-validation-c3c70e8ab378"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import probplot \n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "probplot(results.resid, plot=ax, fit=True) # the .resid attribute contains a numpy array of the residuals\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linearity & Non-constant variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "plt.scatter(results.fittedvalues, results.resid)\n",
    "ax.set_xlabel('fitted values')\n",
    "ax.set_ylabel('residuals')\n",
    "ax.axhline(linewidth=1, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3**: \n",
    "* Reproduce the plots above but for the model that used differenced data that you produced earlier\n",
    "* What would you conclude from each of these plots? Does your fitted model satisfy all of the assumptions to mean it is trustworthy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable selection\n",
    "\n",
    "Usually we may have multiple measurements and we are unsure which are able to best explain the variable we are trying to predict. Then we use *multiple* linear regression to determine which variables are important.\n",
    "\n",
    "For example we can consider the effect of advertising budgets for various media on overall sales of a product. See **ISLR** chapter 3. Here TV, Radio and Newspaper are individual advertising budgets and sales is the total numbers of a produce sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import advertising data\n",
    "advertising = pd.read_csv('./data/Advertising.csv', usecols=[1,2,3,4])\n",
    "advertising.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use statsmodels to fit a *multiple* linear regression model using the same code as before. It will take a 1-d array as the $Y$ variable, and a 2-d numpy matrix for the $X$ vars (where each column represents the data associated with $X1, X2, ...X_{p}$). \n",
    "\n",
    "**Note: we are now passing a pandas series (for $Y$, 1d), and a pandas dataframe(for $X$, 2d). This is much more convenient as statsmodels knows to use the series/dataframe titles as labels for our summary output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_linear_regression(Y,X):\n",
    "    \"\"\"\n",
    "    Function performs linear regression, prints adjusted r-squared and coef table, and returns the model results object.\n",
    "    \n",
    "    Input\n",
    "    =====\n",
    "    Y, pandas series,\n",
    "    X, pandas dataframe,\n",
    "    \n",
    "    Return\n",
    "    ======\n",
    "    results, statsmodel linear regression results object\n",
    "    \n",
    "    \"\"\"\n",
    "    # fit multiple linear regression model\n",
    "    X = sm.add_constant(X) # an intercept term to the model\n",
    "    model = sm.OLS(Y, X)\n",
    "    results = model.fit()\n",
    "    # print results\n",
    "    print('Adjusted R-squared: {0:1.3f}'.format(results.rsquared_adj))\n",
    "    print(results.summary().tables[1])\n",
    "    return(results)\n",
    "\n",
    "\n",
    "sales = advertising['Sales']\n",
    "media_budgets = advertising[['TV','Radio','Newspaper']]\n",
    "\n",
    "results = perform_linear_regression(sales, media_budgets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In selecting a good model that only uses important media budget variables to explain the relationship of sales we would probably remove the Newspaper variable from our model (see chapter 3 for a detailed explantion of this). As you can see below the adjusted r-squared value is similar, and so we have not lost any information in our model. This was a good decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = advertising['Sales']\n",
    "media_budgets = advertising[['TV','Radio']]\n",
    "\n",
    "results = perform_linear_regression(sales, media_budgets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automating variable selection\n",
    "\n",
    "Sometimes we have too many variables to manually check every possible combination of variables. The number of possible models quickly gets out of hand because there are $2^p$ models that contain subsets of $p$ variables. This means that even for moderate $p$, trying out every possible subset of the variables is infeasible. For instance, we saw that if $p = 2$, then\n",
    "there are $2^2 = 4$ models to consider. But if $p = 30$, then we must consider $2^{30} = 1,073,741,824$ models!\n",
    "\n",
    "One classical method for variable selection is *backward selection*. Here we start with all variables in the model, and backward remove the variable with the largest p-value ‚Äî that is, the variable selection that is the least statistically significant. The new $(p ‚àí 1)$-variable model is fit, and the variable with the largest p-value is removed. This\n",
    "procedure continues until a stopping rule is reached. For instance, we may stop when all remaining variables have a p-value below some threshold. (see **ISLR** section 3.2 'Two: deciding on important varaibles' for more info)\n",
    "\n",
    "### Exercise 3: Finding alcohol content of wine using other characteristics\n",
    "\n",
    "You will find a data set containing attributes of different types of wine in `wine.csv` in the data folder. Your task is to find which other variables are important in explaining the alcohol content.\n",
    "\n",
    "You must:\n",
    "* perform a linear regression using all the variables\n",
    "* write a piece of code to implement backwards selection.\n",
    "\n",
    "Your solution, at each stage of the selection, must:\n",
    "* print the name of the variable removed\n",
    "* print the adjusted r-squared\n",
    "* return the coefficient and p-value results of each variable\n",
    "\n",
    "You must use your code output to answer:\n",
    "* How many variables have been removed to end with only significant variables?\n",
    "* Which variables remain in your model?\n",
    "\n",
    "HINT\n",
    "* assume the stopping rule is that you stop when there are only significant varaibles contained in your model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task EXTRA (if you have time left and motivated)**\n",
    "\n",
    "In-depth: OLS with linear algebra. In matrix form OLS is written as:\n",
    "\n",
    "\n",
    "<div style=\"font-size: 120%;\">  \n",
    "Y = X Œ≤ + œµ \n",
    "</div>\n",
    "\n",
    "The $Œ≤$ 's in this case are the same as the coefficients in the statsmodel. To get the $Œ≤$ array:\n",
    "\n",
    "$$ Œ≤ = (1 / (X^T X))  (X^T Y) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25)\n",
    "x = np.random.normal(size = 40)\n",
    "y = 1.6*x + np.random.normal(size = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here: use the numpy package for linear algebra / matrix operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task EXTRA** \n",
    "\n",
    "Understanding normality plot -- define method and code. Write your own code to plot normality of the residual\n",
    "\n",
    "üåö https://dodona.ugent.be/nl/activities/1859394339/#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linear regression models the relationship between an output (dependent) variable Y and one or more input (independent) variables X using the following equation:\n",
    "> **Y= Œ≤0 ‚Äã+ Œ≤1*‚ÄãX1 ‚Äã+ Œ≤2*‚ÄãX2 ‚Äã+ ... + Œ≤p*‚ÄãXp ‚Äã+ œµ**\n",
    "\n",
    "* Œ≤0‚Äã, Œ≤1‚Äã, ‚Ä¶, Œ≤p‚Äã are the regression **coefficients**, representing the estimated effect of each predictor on Y. These are the parameters we aim to estimate.\n",
    "\n",
    "* œµ is the **error term**, capturing the variability in Y not explained by the model.\n",
    "\n",
    "* **R¬≤** measures the proportion of variance in Y that is explained by the predictors X. It ranges from 0 to 1, where higher values indicate a better fit.\n",
    "\n",
    "* The **p-values** give the significance of predictors (null hypothesis: coefficient = 0).\n",
    "\n",
    "* Key **assumptions** of linear regression include:\n",
    "> 1. Linearity: The relationship between X and Y is linear.\n",
    "> 2. Independence of errors: Residuals are uncorrelated.\n",
    "> 3. Homoscedasticity: Residuals have constant variance across all levels of X.\n",
    "> 4. Normality of residuals: Residuals are approximately normally distributed.\n",
    "> 5. No multicollinearity: Predictors are not highly correlated with each other.\n",
    "\n",
    "These assumptions are typically verified using **residual plots** and statistical tests to ensure the validity and reliability of the regression model.\n",
    "\n",
    "* In Python, several libraries can perform linear regression. **statsmodels** is particularly useful for obtaining detailed results, including R¬≤ and adjusted R¬≤, coefficients and their statistical significance (p-values), and diagnostics for checking model assumptions.\n",
    "\n",
    "* To avoid overfitting, it is important to retain only predictors that have a significant impact on Y. Methods like **backward selection** (iteratively removing the least significant predictors) can help achieve a parsimonious model.\n",
    "\n",
    "* Linear regression is both used with a classical statistical approach (understanding and quantifying the relationship between Y and X) and Machine Learning approach (focuses on accurate prediction of Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.825px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
